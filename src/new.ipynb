{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfe29c3f-4345-41ae-a2ae-f358f93037a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %pip install -q mlflow==2.18.0 databricks-vectorsearch==0.40 databricks-sdk==0.38.0 langchain==0.3.0 langchain-community==0.3.0 mlflow[databricks] databricks-agents==0.11.0 langchain_databricks==0.1.1 langgraph==0.2.53 databricks-langchain beautifulsoup4\n",
    "# MAGIC dbutils.library.restartPython()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "#TODO:\n",
    "####CHANGE ME\n",
    "\n",
    "#Timezone that you want to use for mlflow logging\n",
    "timezone_for_logging = \"US/Central\"\n",
    "logging_timezone = pytz.timezone(timezone_for_logging)\n",
    "\n",
    "#catalog to use for creating data tables and keeping other resources\n",
    "#You need necessary privileges to create, delete tables, functions, and models\n",
    "# catalog = \"felixflory\"\n",
    "\n",
    "#schema to use for creating data tables and keeping other resources\n",
    "#You need necessary privileges to create, delete tables, functions, and model\n",
    "# schema = \"covid_trials\" # \"\"\n",
    "\n",
    "#The Volume folder where data file will be copied to\n",
    "# data_folder = \"data\"\n",
    "\n",
    "#the covid data file\n",
    "# covid_data_file_name = \"COVID clinical trials.csv\"\n",
    "\n",
    "#covid cleaned data table name\n",
    "# covid_data_table_name = \"covid_data\"\n",
    "\n",
    "#MLflow experiment tag\n",
    "experiment_tag = f\"databricks_genai_hackathon\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "current_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "project_root_path = \"/\".join(current_path.split(\"/\")[1:-2])\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "db_host_name = spark.conf.get('spark.databricks.workspaceUrl')\n",
    "db_host_url = f\"https://{db_host_name}\"\n",
    "db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "user_email = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "user_name = user_email.split('@')[0].replace('.','_')\n",
    "user_prefix = f\"{user_name[0:4]}{str(len(user_name)).rjust(3, '0')}\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "#Create mlflow experiment\n",
    "import mlflow\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "mlflow_experiment_base_path = f\"Users/{user_email}/mlflow_experiments\"\n",
    "\n",
    "def set_mlflow_experiment(experiment_tag):\n",
    "    w = WorkspaceClient()\n",
    "    w.workspace.mkdirs(f\"/Workspace/{mlflow_experiment_base_path}\")\n",
    "    experiment_path = f\"/{mlflow_experiment_base_path}/{experiment_tag}_{user_prefix}\"\n",
    "    return mlflow.set_experiment(experiment_path)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# print(f\"Using catalog: {catalog}\")\n",
    "# print(f\"Using schema: {schema}\")\n",
    "# print(f\"Project root: {project_root_path}\")\n",
    "print(f\"MLflow Experiment Path: {mlflow_experiment_base_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "new",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
