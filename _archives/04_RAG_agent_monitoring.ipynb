{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2332a5ed-a639-4ef7-a444-d20a58d26652",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Monitoring for Agent Framework\n",
    "\n",
    "When you deploy your agent with databricks.agents.deploy() it will automatically setup a monitor associated with the given mlflow experiment. This code show how to update that monitor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc6ba8e9-0ba7-4618-a3fc-2bdf30c4611a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -q databricks-agents>=0.18.1 mlflow\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0241aed3-3267-4430-9346-8885e3bf6162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.agents import list_deployments, get_deployments, delete_deployment\n",
    "import mlflow\n",
    "from src.utils import set_mlflow_experiment\n",
    "from configs.project import get_project_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e190029-71eb-4335-926f-44a4902e3dd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "projectConfig = get_project_config()\n",
    "\n",
    "config_file = \"../configs/rag_agent.yaml\"\n",
    "multi_agent_config = mlflow.models.ModelConfig(development_config=\"../configs/rag_agent.yaml\")\n",
    "experiment = set_mlflow_experiment(multi_agent_config.get(\"databricks_resources\").get(\"mlflow_experiment_name\"))\n",
    "\n",
    "model_name = multi_agent_config.get(\"databricks_resources\").get(\"model_name\")\n",
    "UC_MODEL_NAME = f\"{projectConfig.uc_catalog}.{projectConfig.uc_schema}.{model_name}\"\n",
    "print(UC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5e18abb-1182-4a56-affd-56d3a77a450d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the deployment for a specific agent model name and version\n",
    "agent_model_name = UC_MODEL_NAME  # Set to your Unity Catalog model name\n",
    "agent_model_version = 1  # Set to your agent model version\n",
    "deployment = get_deployments(model_name=agent_model_name, model_version=agent_model_version)[0]\n",
    "\n",
    "endpoint_name = deployment.__dict__.get(\"endpoint_name\")\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51baa5b5-0739-4224-88eb-0de1c621cb5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.agents.monitoring import update_monitor\n",
    "\n",
    "#update the monitor\n",
    "monitor = update_monitor(\n",
    "    endpoint_name = endpoint_name,\n",
    "    monitoring_config = {\n",
    "        \"sample\": 1.0,  # Sample all requests - DEMO ONLY\n",
    "        \"metrics\": ['guideline_adherence', 'groundedness', 'safety', 'relevance_to_query'],\n",
    "        \"global_guidelines\": {\n",
    "            \"english\": [\"The response must be in English\"],\n",
    "            \"clarity\": [\"The response must be clear, coherent, and concise\"],\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16f9a61-3369-4e37-8993-7858527a8436",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(monitor.evaluated_traces_table).filter(\"evaluation_status != 'skipped'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da3bb9f9-3e96-4de7-95e9-a56e5b12f3a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.agents.monitoring import create_monitor\n",
    "\n",
    "#create monitor; this is not needed if you deployed the model with agents_deploy on databricks-agents >0.18.0\n",
    "# TODO: set experiment_id\n",
    "if False:\n",
    "    monitor = create_monitor(\n",
    "        endpoint_name = endpoint_name,\n",
    "        monitoring_config = {\n",
    "            \"sample\": 1.0, \n",
    "            \"metrics\": ['guideline_adherence', 'groundedness', 'safety', 'relevance_to_query'],\n",
    "            \"global_guidelines\": {\n",
    "                \"english\": [\"The response must be in English\"],\n",
    "                \"clarity\": [\"The response must be clear, coherent, and concise\"],\n",
    "            }\n",
    "        },\n",
    "        experiment_id=\"123...\" #optional config to log monitor to an experiment\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04_RAG_agent_monitoring",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
